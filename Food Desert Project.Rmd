---
title: "Food Deserts in the United States"
author: "Team B"
date: "7/28/2020"
output: 
  html_document:
   code_folding: hide
   number_sections: true
   toc: yes
   toc_depth: 3
   toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }

unloadPkg = function(pkg, character.only = FALSE) { 
  if(!character.only) { pkg <- as.character(substitute(pkg)) } 
  search_item <- paste("package", pkg,sep = ":") 
  while(search_item %in% search()) { detach(search_item, unload = TRUE, character.only = TRUE) } 
}
```


```{r base_lib, include=FALSE}
loadPkg("xtable")
loadPkg("kableExtra")
loadPkg("stringi")
loadPkg("leaps")
loadPkg("ggplot2")
loadPkg("ggmap")
loadPkg("ISLR")
loadPkg("faraway")
loadPkg("tigris")
loadPkg("acs")
loadPkg("stringr") 
loadPkg("ggpubr")
loadPkg("dplyr")
loadPkg("leaps")
loadPkg("MASS")
loadPkg("corrplot")
loadPkg("AICcmodavg")

xkabledply = function(modelsmmrytable, title="Table", digits = 4, pos="left", bso="striped", wide=FALSE) { 
  #' Combining base::summary, xtable, and kableExtra, to easily display model summary. 
  #' wrapper for the base::summary function on model objects
  #' Can also use as head for better display
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param modelsmmrytable This can be a generic table, a model object such as lm(), or the      summary of a model object summary(lm()) 
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @param wide print table in long (FALSE) format or wide (TRUE) format
  #' @return HTML table for display
  #' @examples
  #' library("xtable")
  #' library("kableExtra")
  #' xkabledply( df, title="Table testing", pos="left", bso="hover" )
  #' xkabledply( ISLR::Hitters[1:5,] )
  if (wide) { modelsmmrytable <- t(modelsmmrytable) }
  modelsmmrytable %>%
    xtable() %>% 
    kable(caption = title, digits = digits) %>%
    kable_styling(bootstrap_options = bso, full_width = FALSE, position = pos)
}

xkabledplyhead = function(df, rows=5, title="Head", digits = 4, pos="left", bso="striped") { 
  xkabledply(df[1:rows, ], title, digits, pos, bso, wide=FALSE)
}

xkabledplytail = function(df, rows=5, title="Tail", digits = 4, pos="left", bso="striped") { 
  trows = nrow(df)
  xkabledply(df[ (trows-rows+1) : trows, ], title, digits, pos, bso, wide=FALSE)
}

xkablesummary = function(df, title="Table: Statistics summary.", digits = 4, pos="left", bso="striped") { 
  #' Combining base::summary, xtable, and kableExtra, to easily display numeric variable summary of dataframes. 
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param df The dataframe.
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @return The HTML summary table for display, or for knitr to process into other formats 
  #' @examples
  #' xkablesummary( faraway::ozone )
  #' xkablesummary( ISLR::Hitters, title="Five number summary", pos="left", bso="hover"  )
  
  s = summary(df) %>%
    apply( 2, function(x) stringr::str_remove_all(x,c("Min.\\s*:\\s*","1st Qu.\\s*:\\s*","Median\\s*:\\s*","Mean\\s*:\\s*","3rd Qu.\\s*:\\s*","Max.\\s*:\\s*")) ) %>% # replace all leading words
    apply( 2, function(x) stringr::str_trim(x, "right")) # trim trailing spaces left
  
  colnames(s) <- stringr::str_trim(colnames(s))
  
  if ( dim(s)[1] ==6 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max') 
  } else if ( dim(s)[1] ==7 ) { rownames(s) <- c('Min','Q1','Median','Mean','Q3','Max','NA') }
  
  xkabledply(s, title=title, digits = digits, pos=pos, bso=bso )
}

xkablevif = function(model, title="VIFs of the model", digits = 3, pos="left", bso="striped", wide=TRUE) { 
  #' Combining faraway::vif, xtable, and kableExtra, to easily display numeric summary of VIFs for a model. 
  #' ELo 202004 GWU DATS
  #' version 1.2
  #' @param model The lm or compatible model object.
  #' @param title Title of table. 
  #' @param digits Number of digits to display
  #' @param pos Position of table, c("left","center","right") 
  #' @param bso bootstrap_options = c("basic", "striped", "bordered", "hover", "condensed", "responsive")
  #' @param wide print table in long (FALSE) format or wide (TRUE) format
  #' @return The HTML summary table of the VIFs for a model for display, or for knitr to process into other formats 
  #' @examples
  #' xkablevif( lm(Salary~Hits+RBI, data=ISLR::Hitters, wide=T ) )
  
  vifs = table( names(model$coefficients)[2:length(model$coefficients)] ) # remove intercept to set column names
  vifs[] = faraway::vif(model) # set the values
  if (wide) { vifs <- t(vifs) }
  xkabledply( vifs, title=title, digits = digits, pos=pos, bso=bso )
}
```

```{r outlierKD2, include=FALSE}
# Fix outliers
# Fix outliers
outlierKD2 <- function(df, var, rm=FALSE) { 
    #' Original outlierKD functino by By Klodian Dhana,
    #' https://www.r-bloggers.com/identify-describe-plot-and-remove-the-outliers-from-the-dataset/
    #' Modified to have third argument for removing outliers inwtead of interactive prompt, 
    #' and after removing outlier, original df will not be changed. The function returns the new df, 
    #' which can be saved as original df name if desired.
    #' Check outliers, and option to remove them, save as a new dataframe. 
    #' @param df The dataframe.
    #' @param var The variable in the dataframe to be checked for outliers
    #' @param rm Boolean. Whether to remove outliers or not.
    #' @return The dataframe with outliers replaced by NA if rm==TRUE, or df if nothing changed
    #' @examples
    #' outlierKD2(mydf, height, FALSE)
    #' mydf = outlierKD2(mydf, height, TRUE)
    #' mydfnew = outlierKD2(mydf, height, TRUE)
    dt = df # duplicate the dataframe for potential alteration
    var_name <- eval(substitute(var),eval(dt))
    na1 <- sum(is.na(var_name))
    m1 <- mean(var_name, na.rm = T)
    par(mfrow=c(2, 2), oma=c(0,0,3,0))
    boxplot(var_name, main="With outliers")
    hist(var_name, main="With outliers", xlab=NA, ylab=NA)
    outlier <- boxplot.stats(var_name)$out
    mo <- mean(outlier)
    var_name <- ifelse(var_name %in% outlier, NA, var_name)
    boxplot(var_name, main="Without outliers")
    hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
    title("Outlier Check", outer=TRUE)
    na2 <- sum(is.na(var_name))
    cat("Outliers identified:", na2 - na1, "\n")
    cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "\n")
    cat("Mean of the outliers:", round(mo, 2), "\n")
    m2 <- mean(var_name, na.rm = T)
    cat("Mean without removing outliers:", round(m1, 2), "\n")
    cat("Mean if we remove outliers:", round(m2, 2), "\n")
    
    # response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
    # if(response == "y" | response == "yes"){
    if(rm){
        dt[as.character(substitute(var))] <- invisible(var_name)
        #assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
        cat("Outliers successfully removed", "\n")
        return(invisible(dt))
    } else {
        cat("Nothing changed", "\n")
        return(invisible(df))
    }
}
```
# Chapter 1: Introduction 
Food insecurity continues to be a pressing issue across the United States. The terminology of ‘food deserts’ has consistently been used to describe neighborhoods with limited access to grocery stores or supermarkets. Studies have shown that the most vulnerable populations reside in areas with limited access to full-service grocery outlets. The literature around food insecurity suggests that food deserts emerge from numerous sources including: urban sprawl, residents’ socioeconomic status, racial disparities, and neighborhood density. Research shows that communities in food deserts are at higher risk of health issues including obesity and diabetes. While food deserts have become a legislative priority to address health inequities, there is no concrete evidence suggesting that increasing access to food retail would improve health issues in these communities. 

The United States Department of Agriculture (USDA) has provided a dataset using Census data from 2010 to identify whether a census tract is in a food desert. Given the abundance of research surrounding food deserts and their impact on the quality of life, our project aims to understand the underlying causes of food deserts. Simply put, it boils down to one question: *what variables impact whether or not a census tract is located in a food desert?* To understand why populations experience health inequities and food insecurity, the underlying causes of food deserts in the United States manifests itself as a focal point of the research conducted. Our analyses will lay the foundation for assessing the root causes of food insecurity. 

The report is organized as follows: 

1. Description of dataset 
2. Exploratory Data Analysis  
3. Heatmaps and Geographic Layout of the Data 
4. Model Building and Logistic Regression 
5. Conclusion 


# Chapter 1.1: Description of Data
The USDA’s dataset originally consisted of 147 variables and 72,864 observations of data on food deserts using the Census 2010 results. For us to both manage and  work effectively with the data, we chose to use 22 variables. However, cutting the variables did not change our total observations. So, we extracted a sample from the overall dataset so R would be able to process the data efficiently and with efficacy. Though we want a smaller sample of data, we have ensure that the information from the original dataset is not lost due to the sampling process. Therefore, we chose to draw our sample data proportionally based on the strata of the State variable. 

We chose to use the State variable because its representation is the most significant and it has obvious levels. The first step conducted was deciding to draw a dataset with a size of 7,280 rows to reflect the original dataset of 72,864 rows. Then we used the *table()* function to see the proportion of the State variable. Unfortunately, our results were not very satisfying. To simplify this process we used the calculations as seen below: ($$n_i$$ is the number of observations for State level i; ceil stands for ceiling function): 
         $$a_i = ceil \left(\frac{n_i}{100}\right) x 10$$
         *N* = $$\sum_{i=1}^{51}n_i = 71,864$$ 
         *A* = $$\sum_{i=1}^{51}a_i = 7,280$$ 
We used the ceiling function because $$a_i$$ not integers; we take ceiling values for $$a_i$$ to protect the integrality of levels with few rows. After this, “Sampling” package was installed loaded, strata() function was used to get stratified samples named as food. (See below for a readout of the dataset’s structure and variable names). However, once we extracted the sample food from the original dataset, we realized that we had 47 observations where all of our variables were zero. To mend this issue in our analysis, we subsetted the *food* data frame to only include variables greater than zero (0>). As expected, this further decreased the data frame to 7,232 variables. For further analysis, we chose Desert as our single dependent variable. 

As per the USDA’s guidelines and definitions, this variable indicates whether a “Census Tract Location” is classified as a food desert. Specifically, this variables measures whether or not there is a full service grocery store in a rural or urban census tract. If an urban census tract does not have a full service grocery store within one mile of the tract then it is a food desert. As such, if a rural census tract does not have  a full service grocery store within 10 miles of the tract then it is a food desert. To ensure that our new dataset was representative of the original data, we looked at the proportions of the data. The original USDA dataset had approximately 12% of it’s observations classified as food deserts, and our extracted data also has only 12% of it’s observations classified as food deserts. This report uses the variable Desert to classify a specific tract as a food desert to run an appropriate analysis to test our hypothesis regarding the causes of food deserts. All of the information in our dataset came from the 2010 Census. Now that we have simplified our dataset and chose to only work with 22 variables, the variable definitons are below. 

1. CensusTract: The Census GEO ID tract number
2. State: The name of the state that census tract is in 
3. Region: The region of the United States that the state is in DC is its own region 
4. Urban: When a census tract has population >= 2,500 people it is recognized as an urban area
5. POP2010: Population count of census tract from 2010 census 
6. OHU2010: Number of occupied housing units in a census tract
7. NUMGQTRS: Number of total population in tract living in group housing quarters
8. Desert: Indicates whether or not census tract is in a food desert (For urban areas a grocery store is not within 1 mile and non-urban or rural areas a grocery store is not within 10 miles) 
9. PovertyRate: The tract population living at or below the poverty rate 
10. MedianFamilyIncome: The tract’s median family income
11. TractLOWI: Total number of the low-income population in the tract 
12. TractKids: Total number of children ages 0-17 in the tract 
13. TractSeniors: Total number of seniors ages 65+ in the tract 
14. TractWhite: Total number of white people in the tract 
15. TractBlack: Total number of black people in the tract 
16. TractAsian: Total number of Asian people in the tract
17. TractNHOPI: Total number of Native Hawaiin or Other Pacific Islander in the tract 
18. TractAIAN: Total number of American Indian and Alaskan Native in tract 
19. Tract0Multir: Total number of multiple race/other race population in tract 
20. TractHispanic: Total number of Hispanic or Latinx population in tract
21. TractHUNV: Total number of housing units without access to a vehicle in tract 
22. TractSNAP: Total number of housing units receiving SNAP benefits in tract

```{r clean data, include= FALSE}
food <- data.frame(read.csv("food.csv"))
food <- subset(food, POP2010 > 1)
food$State<-as.factor(food$State)
food$Region <- as.factor(food$Region)
food$Urban <- as.factor(food$Urban)
colnames(food)[8] <- c("Desert")
str(food)
```

# Chapter 2: Exploratory Data Analysis 
## Histograms and Q-Q Plots
Here we are looking at the normality of our quantitative independent variables to assess whether or not we should exclude outliers when we build our model. We are assesisng the normality of our variables from histograms and Q-Q plots. 

### Poverty Rate Normality Test 
```{r Poverty Rate Normality}
summary(food$PovertyRate)
hist(food$PovertyRate, main="Histogram of Percentage of Tract at or Below Federal Poverty Rate", xlab="Poverty Rate", col="purple")
qqnorm(food$PovertyRate, main="Q-Q plot of Percentage of Tract at or Below Poverty Rate")
qqline(food$PovertyRate)
```
The Poverty Rate variable shows a right-skewed distribution which matches our statistical summary of the data points with the mean being larger than the median. This distribution shows us that our data points for this variable are positive. 

### Poverty Rate Normality Test of only Food Deserts
```{r}
food.desert <- subset(food, Desert==1)
hist(food.desert$PovertyRate, main="Histogram of the Percentage of Tract at or Below Poverty Rate in a Food Desert", xlab= "Poverty Rate", col="blue")
qqnorm(food.desert$PovertyRate, main="Percentage of Tract in Food Desert at or Below Poverty Rate")
qqline(food.desert$PovertyRate)
```
When we subset our data to only census tracts that are located in food deserts the mean is 26.97 which means about 27% of households located in a food desert are at or below the federal poverty rate. This is interesting to note, because it shows us that people who are located in food deserts are on average are more likely to be at or below the federal poverty rate level than those who are not located in food deserts. Nonetheless, the Histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive. 

### Finding Outliers 
```{r}
outlierKD2(food, PovertyRate, FALSE)
outlierKD2(food.desert, PovertyRate, FALSE)
```
When we look at the outliers in our *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is about 16% and without outliers it is about 15% so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 26.97 to 25.42 so there is no significant change in removing outliers within this subset. After we remove the outliers from both data frames we can see that our Histogram and is still right-skewed or positive. 

### Population Normality Test 
```{r Population Normality }
summary(food$POP2010)
hist(food$POP2010, main="Histogram of Population in Tract", xlab="Population", col="red")
qqnorm(food$POP2010, main="Q-Q Plot of Tract Population")
qqline(food$POP2010)
```
The Population variable shows a right-skewed distribution from the Histogram and Q-Q plot. This matches our statistical summary of the data points, with the mean being larger than the median. This distribution shows us that our data points for this variable are positive. 

### Population Normality Test of only Food Deserts 
```{r}
hist(food.desert$POP2010, main="Histogram of Population of Tract in Food Desert", xlab="Population", col="yellow")
qqnorm(food.desert$POP2010, main="Q-Q Plot of Food Desert Population Tract")
qqline(food.desert$POP2010)
summary(food.desert$POP2010)
```
When we subset our data to only census tracts that are located in food deserts the mean is 4,360 which is actually higher than the population mean of all census tracts. However, the Histogram and Q-Q plot show us that even after subsetting the data it is still right-skewed or positive.

### Finding Outliers
```{r}
outlierKD2(food, POP2010, rm=FALSE)
outlierKD2(food.desert, POP2010, rm=FALSE)
```
When looking at the *food* data the results show that when we remove our outliers the data becomes more condensed, but the distribution is still right-skewed or positive. When looking at the outliers in locations that are considered food deserts our mean with outliers is 4,360 and without outliers is 4,254. Though with and without outliers our distribution is still slightly skewed to the right. 

### Occupied Housing Units Normality Test 
```{r Occupied Housing Normality Test}
summary(food$OHU2010)
hist(food$OHU2010, main="Histogram of Housing Units", xlab="Occupied Housing Units", col="orange")
qqnorm(food$OHU2010, main="Q-Q Plot of Housing Units")
qqline(food$OHU2010)
```
The total occupied housing units variable shows a right-skewed distribution which matches our statistical summary of the data points, with the mean being larger than the median. This distribution shows us that our data points for this variable are positive.

### Occupied Housing Units Normality Test of only Food Deserts
```{r}
summary(food.desert$OHU2010)
hist(food.desert$OHU2010, main="Histogram of Occupied Housing Units in Food Deserts", xlab="Occupied Housing Units", col="pink")
qqnorm(food.desert$OHU2010, main="Q-Q Plot of Housing in Food Desert")
qqline(food.desert$OHU2010)
```
When we subset our data to only census tracts that are in food deserts and look at the total occupied housing units  our summary statistics make for an interesring comparison. The max amount of occupied housing in our *food* data is 12,426 but in the subsetted data frame the max amount of occupied housing is only 4,772 this is about a 60% decrease in occupied housing units. Furthermore, when we subsetted the data and are looking at the distribution of occupied housing units in food deserts we can tell from our Q-Q plot and histogram that our variable is now normally distributed. 

### Finding Outliers 
```{r}
outlierKD2(food, OHU2010, rm=FALSE)
outlierKD2(food.desert, OHU2010, rm=FALSE)
```
When we look at the outliers of the *food* data the mean with the outliers is 1,615 and without outliers the mean is 1,571 so nothing really changes by removing the outliers. Also, with and without outliers the distribution is skewed to the right. When looking at the outliers in our subset that only incldues tracts in food deserts we can see that there are only 10 outliers. The mean with the outliers is 1,605 and without outliers is 1,579 so nothing really changes by removing the outliers.

### Group Housing Units Normality Test 
```{r Group Housing Normality Test}
summary(food$NUMGQTRS)
hist(food$NUMGQTRS, main="Histogram of Group Housing Units", xlab="Group Housing Units", col="dark green")
qqnorm(food$NUMGQTRS, main="Q-Q Plot of Group Housing Units")
qqline(food$NUMGQTRS)
```
The Group Housing units variable shows a right-skewed distribution which matches our statistical summay of the data points with the mean being larger than the median. This histogram and Q-Q Plot show that this variable has a right-skewed or positive distribution. What is interesting to note about this variable in our data is that the range is so big. Our minimum amount of group housing units is zero and then our maximum is 11,777. This seems extreme and likely that we would have outliers within these data points, but we will assess this further when executing the outlier function below. 

### Group Housing Units Normality Test for only food deserts
```{r} 
summary(food.desert$NUMGQTRS)
hist(food.desert$NUMGQTRS, main="Histogram of Group Housing Units in Food Deserts", xlab=" Group Housing Units", col="light blue ")
qqnorm(food.desert$OHU2010, main="Q-Q Plot of Housing in Food Desert")
qqline(food.desert$OHU2010)
```
When we subset our data to only census tracts that are located in food deserts the mean increases from 110 in our *food* data to an average of 200 group housing units in food deserts. However, the range for the subsetted data is still 0-11,777 even though the histogram does not do a great job of visualizing the range. Again, we would assume that this variable has outliers that should be taken out. Though the Q-Q plot of the subsetted data resembles a straight line more so than the the Q-Q plot of the *food* data, the histogram still shows a right-skewed or positive distribution.

### Finding Outliers 
```{r}
outlierKD2(food, NUMGQTRS, rm=FALSE)
outlierKD2(food.desert, NUMGQTRS, rm=FALSE)
```
When we look at the group housing outliers in the *food* data there are 831. The mean of the data with the outliers is 110 and without the outliers the mean is 24. This is a pretty big drop in the mean than from the other variables that we have seen, but nonetheless the data still has a right-skewed distribution and would yield the same results before and after the removal of outliers. When we are looking at the outliers from the subset of group housing units in food deserts the mean also has a big drop. With the outliers the mean is 200 and without outliers the mean is 42. However, the distribution is still right-skewed and would yield the same results. It feels like we should remove the outliers because the range is so long, but because the results of still show a right-skewed or positive distribution, nothing changes with the removal of outliers.

### Median Family Income Normality Test 
```{r Median Family Income Normality Test}
summary(food$MedianFamilyIncome)
hist(food$MedianFamilyIncome, main="Histogram of Median Family Income", xlab="Median Family Income", col="dark blue")
qqnorm(food$MedianFamilyIncome, main="Q-Q Plot of Median Family Income")
qqline(food$MedianFamilyIncome)
```
The median family income variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. This distribution shows us that our data points for this variable are positive. 

### Median Family Income Normality Test of only Food Deserts 
```{r}
summary(food.desert$MedianFamilyIncome)
hist(food.desert$MedianFamilyIncome, main="Histogram of Median Family Income in Food Deserts", xlab= "Median Family Income", col="dark red")
qqnorm(food.desert$MedianFamilyIncome, main="Q-Q Plot of Median Family Income in Food Deserts")
qqline(food.desert$MedianFamilyIncome)
```
When we subset our data to only census tracts that are located in food deserts the mean of the median family income decreased by more than \$20,000 showing about a 35% decrease in median family income. Further more, the maximum amount went from \$250,000 to \$140,250. Nonetheless,   the distribution of the median family income for tracts that are located in food deserts is right-skewed or positive. Though, compared to the *food* data, the Q-Q plot does resemble more of a straight line, but is still right-skewed.

### Finding Outliers 
```{r}
outlierKD2(food, MedianFamilyIncome, rm=FALSE)
outlierKD2(food.desert, MedianFamilyIncome, rm=FALSE)
```
When we look at the outliers in our *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is \$67,768  and without outliers it is about \$63,630 so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from \$43,580 to \$42,882 so there is no significant change in removing outliers within the subset. Therefore, nothing really changes with the removal of outliers. The distribution of the data is still right-skewed and positive, even though it is not as far right-skewed as before the removal. 
### Low-Income Population Normality Test 
```{r Low-Income Population Normality Test}
summary(food$TractLOWI)
hist(food$TractLOWI, main="Histogram of Low-Income Population", xlab= "Low-Income Population", col="light green")
qqnorm(food$TractLOWI, main="Q-Q Plot of Low-Income Population")
qqline(food$TractLOWI)
```
The low-income tract variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. This distribution shows us that our data points for this variable are positive. 

### Low-Income Population Normality Test of only Food Deserts 
```{r}
summary(food.desert$TractLOWI)
hist(food.desert$TractLOWI, main="Histogram of Low-Income Population in Food Deserts", xlab="Low-Income Population", col="red")
qqnorm(food.desert$TractLOWI, main="Q-Q Plot of   Low-Income Population in Food Deserts")
qqline(food.desert$TractLOWI)
```
When we subset our data to only census tracts that are located in food deserts the mean of the low-income population is 2,192, which is 719 more than the mean from the *food* data. This is interesting because the subsetted data has fewer data points and a smaller maximum but the mean of low-income people in food deserts is higher. Nonetheless, the histogram and Q-Q plot of this variable shows us that the distribution is still right-skewwed or positive.

### Finding Outliers 
``` {r} 
outlierKD2(food, TractLOWI, rm=FALSE)
outlierKD2(food.desert, TractLOWI, rm=FALSE)
```
When we look at the outliers in our *food* data we can see that the distribution is still right-skewed with and without outliers. Furthermore, the mean with outliers is about 1,472 and  and without outliers it is 1,353 so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 2,192 to 2,075 so there is no significant change in removing outliers within this subset. Additionally, before and after the removal of outliers in the *food* data and subsetted data the distribution is still right-skewed or positive. 

### Kid Count Normality Test 
```{r Kid Count Normality Test}
summary(food$TractKids)
hist(food$TractKids, main="Histogram of Kid Count", xlab="Total Amount of Kids", col="purple")
qqnorm(food$TractKids, main="Q-Q Plot of Kid Count in Tract")
qqline(food$TractKids)
```
The total kid count variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. This distribution shows us that our data points for this variable are positive.

### Kid Count Normality Test of only Food Deserts 
```{r}
summary(food.desert$TractKids)
hist(food.desert$TractKids, main="Histogram of Kid Count in Food Deserts", xlab="Total Amount of Kids", col="yellow")
qqnorm(food.desert$TractKids, main="Q-Q Plot of Kid Count Population in Food Deserts")
qqline(food.desert$TractKids)
```
When we subset our data to only census tracts that are located in food deserts the mean is 1,097 and the mean of the *food* data is 1,025 and there is an increase but not a significant increase in the mean of the data. However, the maximum amount of kids in the *food* data is 9,377 and for the subsetted data the total is 5,938 - though this makes sense because the subsetted data has significanlty smaller datapoints than *food*. Nonetheless, the Histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive. 

### Finding Outliers 
```{r} 
outlierKD2(food, TractKids, rm=FALSE)
outlierKD2(food.desert, TractKids, rm=FALSE)
```
When we look at the outliers in our *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is 1,025 and without outliers it is 960 so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 1,097 to 1,026 which is definelty not a significant change. After we remove the outliers from both data frames we can see that our data is still right-skewed or positive; so essentially nothing changes. 

### Senior Count Normality Test 
```{r Senior Count Normality Test}
summary(food$TractSeniors)
hist(food$TractSeniors, main="Histogram of Seniors in Tract", xlab="Total Amount of Seniors", col="brown")
qqnorm(food$TractSeniors, main="Q-Q Plot of Seniors in Tract")
qqline(food$TractSeniors)
```
The variable for the total amount of seniors shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. This distribution shows us that our data points for this variable are positive. 

### Senior Count Normality Test of only Food Deserts 
```{r}
summary(food.desert$TractSeniors)
hist(food.desert$TractSeniors, main="Histogram of Seniors in Food Deserts", xlab="Total Amount of Seniors", col="pink")
qqnorm(food.desert$TractSeniors, main="Q-Q Plot of Seniors in Food Deserts")
qqline(food.desert$TractSeniors)
```
When we subset our data to only census tracts that are located in food deserts the mean is 538 which is pretty close to the mean of total senior count in the *food* data of 561. As such, one could assume that this variable is not too different based on whether or not a census tract is located in a food desert. However, the only way we can prove this is when run a regression later on in the analysis. Nonetheless, the histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive. 

### Finding Outliers 
```{r}
outlierKD2(food, TractSeniors, rm=FALSE)
outlierKD2(food.desert, TractSeniors, rm=FALSE)
```
When we look at the outliers in our *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. The difference without outliers shows a wider distribution but still right-skewed. Furthermore, the mean with outliers is 561 and without outliers it is 524, so there is essentially no change from the removal of outliers. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 538 to 502 so there is no significant change in removing outliers within this subset. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### White Population Normality Test 
```{r White Population Normality Test}
summary(food$TractWhite)
hist(food$TractWhite, main="Histogram of White Population", xlab="Total White Population", col="orange")
qqnorm(food$TractWhite, main="Q-Q Plot of White Population")
qqline(food$TractWhite)
```
The white population variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. The distribution shows us that our data points for this variable are positive. 

###  White Populatin Normality Test in only Food Deserts 
```{r} 
summary(food.desert$TractWhite) 
hist(food.desert$TractWhite, main="Histogram of White Population in Food Deserts", xlab="Total White Population", col="dark green")
qqnorm(food.desert$TractWhite, main="Q-Q Plot of White Population in Food Deserts")
qqline(food.desert$TractWhite)
```
When we subset our data to only census tracts that are located in food deserts the mean is 2,782 which is 300 smaller than the mean of the white population in the *food* data. However, what is interesting is to note that the maximum of the white population in our *food* data is about 37% larger than the subsetted data that only includes census tracts in food deserts. Nonetheless, the histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive when looking at only census tracts in food deserts. 

### Finding Outliers 
```{r} 
outlierKD2(food, TractWhite, rm=FALSE)
outlierKD2(food.desert, TractWhite, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is 3,081 and without outliers it is 2,984 which is not a large change. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 2,781 to 2,698 so there is no significant change in removing outliers within the subset. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### Black Population Normality Test 
```{r Black Population Normality Test}
summary(food$TractBlack)
hist(food$TractBlack, main="Histogram of Black Population", xlab="Total Black Population", col="dark red")
qqnorm(food$TractBlack, main="Q-Q Plot of Black Population")
qqline(food$TractBlack)
```
The black population variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. The distribution shows us that our data points for this variable are positive. 

### Black Population Normality Test of only Food Deserts 
```{r}
summary(food.desert$TractBlack)
hist(food.desert$TractBlack, main="Histogram of Black Population in Food Deserts", xlab="Total Black Population", col="red")
qqnorm(food.desert$TractBlack, main="Q-Q Plot of Black Population in Food Deserts")
qqline(food.desert$TractBlack)
```
When we subset our data to only census tracts that are located in food deserts the mean is 930  which is about 40% larger than the mean of the black population in the *food* data. This is interesting to note, because it shows us that the amount of black people in a census tract increased proportionally when classified as a food desert. Nonetheless, the Histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive. 

### Finding Outliers 
```{r}
outlierKD2(food, TractBlack, rm=FALSE)
outlierKD2(food.desert, TractBlack, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is 546 and without outliers it is 276 which is a pretty big drop, but it is not sufficient enough for us to see a change in the distribution. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 930 to 742 which is also a big drop, but does not change the distribution. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### Asian Population Normality Test 
```{r Asian Population Normality Test}
summary(food$TractAsian)
hist(food$TractAsian, main="Histogram of Asian Population", xlab="Total Asian Population", col="dark orange")
qqnorm(food$TractAsian, main="Q-Q Plot of Asian Population")
qqline(food$TractAsian)
```
The asian population variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. The distribution shows us that our data points for this variable are positive. 

### Asian Population Normality Test of only Food Deserts 
```{r} 
summary(food.desert$TractAsian)
hist(food.desert$TractAsian, main="Histogram of Asian Population in Food Deserts",xlab="Total Asian Population", col="green")
qqnorm(food.desert$TractAsian, main="Q-Q Plot of Asian Population in Food Deserts")
qqline(food.desert$TractAsian)
```
When we subset our data to only census tracts that are located in food deserts the mean is 95 which is only slightly smaller than the mean of the asian population of the *food* data. Nonetheless, the Histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive. 

### Finding Outliers 
```{r}
outlierKD2(food, TractAsian, rm=FALSE)
outlierKD2(food.desert, TractAsian, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is about 201 and without outliers it is 88, which seems like a large drop, but it is not sufficient enough to change the distribution. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 95 to 38, but this is not a significant change. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### Native Hawaiian or Pacific Islander Normality Test 
```{r Native Hawaiian and Pacific Islander Normality Test}
summary(food$TractNHOPI)
hist(food$TractNHOPI, main="Histogram of Native Hawaiian or Pacific Islander  Population", xlab="Total Native Hawaiian or Pacific Islander Population", col="blue")
qqnorm(food$TractNHOPI, main="Q-Q Plot of Native Hawaiian or Pacific Islander Population")
qqline(food$TractNHOPI)
```
The Native Hawaiian or Pacific Islander variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. The distribution shows us that our data points for this variable are positive. 

### Native Hawaiian or Pacific Islander Population Normality Test for only Food Deserts 
```{r} 
summary(food.desert$TractNHOPI)
hist(food.desert$TractNHOPI, main="Histogram of Native Hawaiian or Pacific Islander Population in Food Deserts", xlab="Total Native Hawaiian or Pacific Islander Population", col="light blue")
qqnorm(food.desert$TractNHOPI, main="Q-Q Plot of Native Hawaiian or Pacific Islander Population in Food Deserts")
qqline(food.desert$TractNHOPI)
```
When we subset our data to only census tracts that are located in food deserts the mean is 8 which is higher than the mean of our *food* data but only by two people. However, what is interesting to note about the subsetted data is that the maximum amount for the *food* data and subset is the same at 1,333. This means that there are 1,333 people who identify as Native Hawaiin or Pacific Islander located in a food desert. Native and indigenous people are a minority population in the United States, and yet the maximum amount of this population from our data do not have access to full service grocery stores. Of course, we do not have enough information to determine if this variable is significant in our analysis but we will discuss this later on in the report. Nonetheless, the Histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive. 

### Finding Outliers 
```{r}
outlierKD2(food, TractNHOPI, rm=FALSE)
outlierKD2(food.desert, TractNHOPI, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is about 6 and without outliers it is only 1, which is not a significant change. When we subset our *food* data to only include food deserts the mean with and without outliers changes from about 8 to about 1, but this is still not a sufficient enough change to impact the distribution. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### American Indian or Alaskan Native Population Normality Test 
```{r American Indian and Alaskan Native Population Normality Test}
summary(food$TractAIAN)
hist(food$TractAIAN, main="Histogram of American Indian and Alaskan Native Population", xlab="Total American Indian or Alaskan Native Population", col="orange")
qqnorm(food$TractAIAN, main="Q-Q Plot of American Indian and Alaskan Native Population")
qqline(food$TractAIAN)
```
The American Indian or Alaskan Native Population variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. The distribution shows us that our data points for this variable are positive. 

### American Indian and Alaskan Native Population Normality Test for only Food Deserts 
```{r}
summary(food.desert$TractAIAN)
hist(food.desert$TractAIAN, main="Histogram of American Indian and Alaskan Native Population in Food Deserts", xlab="Total American Indian or Alaskan Native Population", col="red")
qqnorm(food.desert$TractAIAN, main="Q-Q Plot of American Indian and Alaskan Native Population in Food Deserts")
qqline(food.desert$TractAIAN)
```
When we subset our data to only census tracts that are located in food deserts the mean is 105 which is more than double the mean of the American Indian or Alaskan Native population in the *food* data. Furthermore, it is interesting to note that with this population like the Native Hawaiin or Pacific Islander variable, that the maximum total is the same for the *food* data and the subsetted data at 9,009. This means that a minority population, who is unproportinally reprsented with the rest of the country, has a higher propbability of being in a food desert--at least from our dataset. However, we do not have enough information to make this claim and will do further analysis on this later on in the report. Nonetheless, the Histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive. 

### Finding Outliers 
```{r}
outlierKD2(food,TractAIAN , rm=FALSE)
outlierKD2(food.desert, TractAIAN, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is about 42 and without outliers it is about 18 so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 105 to 22, which seems like a big change, but it is not significant enoguh to impact the distribution. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### Mutliple Races or Other Race Population Normality Test 
```{r Multiple race/other race population Normality Test}
summary(food$TractOMultir)
hist(food$TractOMultir, main="Histogram of Multiple race/other race population", xlab="Mixed Race or Other Race population", col="orange")
qqnorm(food$TractOMultir, main="Q-Q Plot of Multiple race/other race population")
qqline(food$TractOMultir)
```
The multiple or other race variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. The distribution shows us that our data points for this variable are positive. 

### Multiple Races or Other Race Population Normality Test for only Food Deserts 
```{r}
summary(food.desert$TractOMultir)
hist(food.desert$TractOMultir, main="Histogram of Multiple race/other race population in Food Deserts", xlab="Mixed Race or Other Race population", col="red")
qqnorm(food.desert$TractOMultir, main="Q-Q Plot of Multiple race/other race population in Food Deserts")
qqline(food.desert$TractOMultir)
```
When we subset our data to only census tracts that are located in food deserts the mean is about 439 which is only slightly larger than the *food* data mean of people who identify as multiple races or other. The nature of this variable is vague because it doesn't specifiy what races one identifies as, and the data source did not do a great job of explaining what is meant by the other aspect of this variable. As such, this variable might not be useful for the anlaysis. However, we do not have enough information to tell at this point and will decide later on in the report. Nonetheless, the Histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive.   

### Finding Outliers 
```{r}
outlierKD2(food, TractOMultir,rm=FALSE)
outlierKD2(food.desert, TractOMultir, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is about 390 and without outliers, it is about 245 so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 439 to 322. Still, there is no significant change in removing outliers within the subset. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 


### Hispanic Population Normality Test 
```{r Hispanic population Normality Test}
summary(food$TractHispanic)
hist(food$TractHispanic, main="Histogram of Hispanic or Latinx population", xlab="Total Hispanic Population", col="orange")
qqnorm(food$TractHispanic, main="Q-Q Plot of Hispanic or Latinx population")
qqline(food$TractHispanic)
```
The Hispanic population variable shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. This distribution shows us that our data points for this variable are positive. 

### Hispanic Population Normality Test for only Food Deserts 
```{r}
summary(food.desert$TractHispanic)
hist(food.desert$TractHispanic, main="Histogram of Hispanic population in Food Deserts", col="red")
qqnorm(food.desert$TractHispanic, main="Q-Q Plot of Hispanic population in Food Deserts")
qqline(food.desert$TractHispanic)
```
When we subset our data to only census tracts that are located in food deserts the mean is 862 which is about 17% larger than the Hispanic population mean in the *food* data. Furthermore, similar to the American Indian and Native Hawaiian population, the maximum amount of the Hispanic population is the same for the *food* data and the subsetted data - meaning that 14,402 people who identify as Hispanic do not have access to a full service grocery store. So far, the exploratory data anlaysis has shown us multiple minority populations with significant increases of population totals in food deserts. We will explore this later on in the report, but just from EDA the literature around food deserts seems to match up with our dat. Nonetheless, the histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive.   

### Finding Outliers 
```{R}
outlierKD2(food,TractHispanic,rm=FALSE)
outlierKD2(food.desert, TractHispanic, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is about 707 and without outliers it is about 359 which seems like a large drop. However, we can see above that the drop does not change the distribution. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 862 to 420 which is more than 50% of a decrease, but still there is no significant change from the distribution. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### Housing Units Without a Vehicle Normality Test 
```{r Housing units without access to a vehicle Normality Test}
summary(food$TractHUNV)
hist(food$TractHUNV, main="Histogram of housing units without access to a vehicle", xlab="Total Hosuing Units without a Vehicle", col="orange")
qqnorm(food$TractHUNV, main="Q-Q Plot of housing units without access to a vehicle")
qqline(food$TractHUNV)
```
The total housing units without access to a vehicle shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. The distribution shows us that our data points for this variable are positive. 

### Housing Units Without a Vehicle Normality Test only for Food Deserts  
```{r}
summary(food.desert$TractHUNV)
hist(food.desert$TractHUNV, main="Histogram of Housing Units without access to a Vehicle in Food Deserts", xlab="Housing Units without access to Vehicle", col="red")
qqnorm(food.desert$TractHUNV, main="Q-Q Plot of housing units without access to a vehicle in Food Deserts")
qqline(food.desert$TractHUNV)
```
When we subset our data to only census tracts that are located in food deserts the mean is 154 which is essentially the same as the mean of the *food* data. Similar to the *food* histogram and Q-Q plot, the histogram and Q-Q plot of this variable in our subsetted data show us that the distribution is still right-skewed or positive.   

### Finding Outliers 
```{r}
outlierKD2(food,TractHUNV,rm=FALSE)
outlierKD2(food.desert, TractHUNV, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is about 150 and without outliers, it is 102 so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 154 to 138, so there is no significant change in removing outliers within the subset. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

### Housing Units Receiving SNAP Normality Test 
```{r housing units receiving SNAP benefits Normality Test}
summary(food$TractSNAP)
hist(food$TractSNAP, main="Histogram of housing units receiving SNAP benefits", xlab="Housing Units Receiving SNAP", col="orange")
qqnorm(food$TractSNAP, main="Q-Q Plot of housing units receiving SNAP benefits")
qqline(food$TractSNAP)
```
The variable for the total amount of housing units receiving SNAP benefits  shows a right-skewed distribution through the histogram and Q-Q plot. This matches our statistical summary of the data points with the mean being larger than the median. This distribution shows us that our data points for this variable are positive. 

### Housing Units Receiving SNAP Normality Test only for Food Deserts 
```{R}
summary(food.desert$TractSNAP)
hist(food.desert$TractSNAP, main="Histogram of housing units receiving SNAP benefits in Food Deserts", xlab= "Housing Units Receiving SNAP", col="red")
qqnorm(food.desert$TractSNAP, main="Q-Q Plot of housing units receiving SNAP benefits in Food Deserts")
qqline(food.desert$TractSNAP)
```
When we subset our data to only census tracts that are located in food deserts the mean is 343 which is about a 38% increase in housing units receiving SNAP benefits from the *food* data. This is interesting to note, because it shows that people who get SNAP benefits are more likely to be located in food deserts at least based on this dataset. However, we still do not have enough evidence to make this claim, and will further explore the relationship between food deserts and housing units getting SNAP benefits throughout the analysis. Nonetheless, the histogram and Q-Q plot of this variable show us that the distribution is still right-skewed or positive.   

### Finding Outliers 
```{r}
outlierKD2(food,TractSNAP,rm=FALSE)
outlierKD2(food.desert,TractSNAP, rm=FALSE)
```
When we look at the *food* data we can see that the distribution is still slightly skewed to the right with and without outliers. Furthermore, the mean with outliers is 210  and without outliers it is 189 so this did not change much. When we subset our *food* data to only include food deserts the mean with and without outliers changes from 343 to 327, so there is no significant change in removing outliers within the subset. The removal of outliers does not change the results of the data points enough to create a normal distribution. We can see that the distribution is still right-skewed or positive with the removal of outliers. 

The results of the normality tests show that the distribution for all of our quantitative variables are positive.  This indicates that the mean for our variables will be greater than the median and that all of our data points are positive.

## Kolmogorov-Smirnov Test 
To make the results of normality test more clear, we tried an another method, the Kolmogorov-Smirnov or K-S test. In addition to the normality tests using graphs, the Kolmogorov Smirnov test is used to give numerical output so we can judge our conclusions above. We did not choose to use the Shapiro Wilk test because it requires the maximum sample size to be less than 5000. The K-S test also has its own restriction, it asks the numbers to be tested are unique (no repeats). So, to avoid warning messages that can affect our outputs in R, we added random numbers from uniform distribution (-0.05, 0.05), since the mean of this distribution is 0, this will not affect our final conclusions about normality tests
```{R Kolmogorov-Smirnov Test}
ks.test(food$PovertyRate+runif(length(food$PovertyRate),-0.05,0.05),"pnorm",mean=mean(food$PovertyRate),sd=sd(food$PovertyRate))

ks.test(food$POP2010+runif(length(food$POP2010),-0.05,0.05),"pnorm",mean=mean(food$POP2010),sd=sd(food$POP2010))

ks.test(food$OHU2010+runif(length(food$OHU2010),-0.05,0.05),"pnorm",mean=mean(food$OHU2010),sd=sd(food$OHU2010))

ks.test(food$NUMGQTRS+runif(length(food$NUMGQTRS),-0.05,0.05),"pnorm",mean=mean(food$NUMGQTRS),sd=sd(food$NUMGQTRS))

ks.test(food$MedianFamilyIncome+runif(length(food$MedianFamilyIncome),-0.05,0.05),"pnorm",mean=mean(food$MedianFamilyIncome),sd=sd(food$MedianFamilyIncome))

ks.test(food$TractLOWI+runif(length(food$TractLOWI),-0.05,0.05),"pnorm",mean=mean(food$TractLOWI),sd=sd(food$TractLOWI))

ks.test(food$TractKids+runif(length(food$TractKids),-0.05,0.05),"pnorm",mean=mean(food$TractKids),sd=sd(food$TractKids))

ks.test(food$TractSeniors+runif(length(food$TractSeniors),-0.05,0.05),"pnorm",mean=mean(food$TractSeniors),sd=sd(food$TractSeniors))

ks.test(food$TractWhite+runif(length(food$TractWhite),-0.05,0.05),"pnorm",mean=mean(food$TractWhite),sd=sd(food$TractWhite))

ks.test(food$TractBlack+runif(length(food$TractBlack),-0.05,0.05),"pnorm",mean=mean(food$TractBlack),sd=sd(food$TractBlack))

ks.test(food$TractAsian+runif(length(food$TractAsian),-0.05,0.05),"pnorm",mean=mean(food$TractAsian),sd=sd(food$TractAsian))

ks.test(food$TractNHOPI+runif(length(food$TractNHOPI),-0.05,0.05),"pnorm",mean=mean(food$TractNHOPI),sd=sd(food$TractNHOPI))

ks.test(food$TractAIAN+runif(length(food$TractAIAN),-0.05,0.05),"pnorm",mean=mean(food$TractAIAN),sd=sd(food$TractAIAN))

ks.test(food$TractOMultir+runif(length(food$TractOMultir),-0.05,0.05),"pnorm",mean=mean(food$TractOMultir),sd=sd(food$TractOMultir))

ks.test(food$TractHispanic+runif(length(food$TractHispanic),-0.05,0.05),"pnorm",mean=mean(food$TractHispanic),sd=sd(food$TractHispanic))

ks.test(food$TractHUNV+runif(length(food$TractHUNV),-0.05,0.05),"pnorm",mean=mean(food$TractHUNV),sd=sd(food$TractHUNV))

ks.test(food$TractSNAP+runif(length(food$TractSNAP),-0.05,0.05),"pnorm",mean=mean(food$TractSNAP),sd=sd(food$TractSNAP))

### For dataset food.desert
ks.test(food.desert$PovertyRate+runif(length(food.desert$PovertyRate),-0.05,0.05),"pnorm",mean=mean(food.desert$PovertyRate),sd=sd(food.desert$PovertyRate))

ks.test(food.desert$POP2010+runif(length(food.desert$POP2010),-0.05,0.05),"pnorm",mean=mean(food.desert$POP2010),sd=sd(food.desert$POP2010))

ks.test(food.desert$OHU2010+runif(length(food.desert$OHU2010),-0.05,0.05),"pnorm",mean=mean(food.desert$OHU2010),sd=sd(food.desert$OHU2010))

ks.test(food.desert$NUMGQTRS+runif(length(food.desert$NUMGQTRS),-0.05,0.05),"pnorm",mean=mean(food.desert$NUMGQTRS),sd=sd(food.desert$NUMGQTRS))

ks.test(food.desert$MedianFamilyIncome+runif(length(food.desert$MedianFamilyIncome),-0.05,0.05),"pnorm",mean=mean(food.desert$MedianFamilyIncome),sd=sd(food.desert$MedianFamilyIncome))

ks.test(food.desert$TractLOWI+runif(length(food.desert$TractLOWI),-0.05,0.05),"pnorm",mean=mean(food.desert$TractLOWI),sd=sd(food.desert$TractLOWI))

ks.test(food.desert$TractKids+runif(length(food.desert$TractKids),-0.05,0.05),"pnorm",mean=mean(food.desert$TractKids),sd=sd(food.desert$TractKids))

ks.test(food.desert$TractSeniors+runif(length(food.desert$TractSeniors),-0.05,0.05),"pnorm",mean=mean(food.desert$TractSeniors),sd=sd(food.desert$TractSeniors))

ks.test(food.desert$TractWhite+runif(length(food.desert$TractWhite),-0.05,0.05),"pnorm",mean=mean(food.desert$TractWhite),sd=sd(food.desert$TractWhite))

ks.test(food.desert$TractBlack+runif(length(food.desert$TractBlack),-0.05,0.05),"pnorm",mean=mean(food.desert$TractBlack),sd=sd(food.desert$TractBlack))

ks.test(food.desert$TractAsian+runif(length(food.desert$TractAsian),-0.05,0.05),"pnorm",mean=mean(food.desert$TractAsian),sd=sd(food.desert$TractAsian))

ks.test(food.desert$TractNHOPI+runif(length(food.desert$TractNHOPI),-0.05,0.05),"pnorm",mean=mean(food.desert$TractNHOPI),sd=sd(food.desert$TractNHOPI))

ks.test(food.desert$TractAIAN+runif(length(food.desert$TractAIAN),-0.05,0.05),"pnorm",mean=mean(food.desert$TractAIAN),sd=sd(food.desert$TractAIAN))

ks.test(food.desert$TractOMultir+runif(length(food.desert$TractOMultir),-0.05,0.05),"pnorm",mean=mean(food.desert$TractOMultir),sd=sd(food.desert$TractOMultir))

ks.test(food.desert$TractHispanic+runif(length(food.desert$TractHispanic),-0.05,0.05),"pnorm",mean=mean(food.desert$TractHispanic),sd=sd(food.desert$TractHispanic))

ks.test(food.desert$TractHUNV+runif(length(food.desert$TractHUNV),-0.05,0.05),"pnorm",mean=mean(food.desert$TractHUNV),sd=sd(food.desert$TractHUNV))

ks.test(food.desert$TractSNAP+runif(length(food.desert$TractSNAP),-0.05,0.05),"pnorm",mean=mean(food.desert$TractSNAP),sd=sd(food.desert$TractSNAP))
```

Here we added runif function to avoid repeat of numbers in variables, repear will lead to an error of K-S test. And since we are using random number generator from uniform distribution, it will not affect our result

Based on the results of K-S tests, the variables ‘OHU2010’ in the dataset ‘food.desert’ showed p-value larger than 0.01, we can say that the variables are normally distributed, but our final conclusions about the rest variables must be made together with graph results.


# Chapter 2.1 Exploratory Data Analysis 
## Chi-Square Test of Independence 
Here we are performing Chi-Square test on the categorical variables in our dataset to determine whether there is a relationship between our indpendent variables and dependent variable. 
```{r}
# Contigency Table of Food Deserts and Urban Tract
contable.urban <- table(food$Urban, food$Desert)
xkabledply(contable.urban, title="Contingency Table for Food Deserts in Urban Tracts")
urban.tble <- chisq.test(contable.urban)
urban.tble
urban.tble$expected
xkabledply(urban.tble$expected, title="Cross table for the Expected Frequencies of Food Deserts in Urban Tracts")
```
Here, we mainly focus on the output of Chi-Square test, we got a test statistic of 53.899 which is larger than 3.84 (95% critical value of 1 df Chi-Square test), and the corresponding p-value is lower than 0.05. Thus, we have enough evidence to reject the null hypothesis. This means that the variables 'Urban' and 'Desert' are not independent of one another and in fact are related. As such, we have a good reason to keep variable 'Urban' in our model, but further investigations are needed.

```{r}
# Contingency Table of Food Deserts and Geographical Region 
contable.region <- table(food$Region, food$Desert)
xkabledply(contable.region, title="Contingency Table for Food Deserts located in Geographical Regions")
region.tble <- chisq.test(contable.region)
region.tble
region.tble$expected
xkabledply(region.tble$expected, title="Cross table for the Expected Frequencies of Food Deserts in Geographical Regions")
```
Focusing on the chi-square test results we can once again reject the null hypothesis that Region and Desert are independent. The output here shows us that the test statistic is 213.41 which is much large than the critical chi-square value for 5 degrees of freedom of 11.07. Additionally, the p-value is smaller than .05 so these results are statistically significant at the 95% probability level. 

```{r}
# Contingency Table of Food Deserts and States
contable.state <- table(food$State, food$Desert)
xkabledply(contable.state, title="Contingency Table for Food Deserts located in U.S. States")
state.tble <- chisq.test(contable.state)
state.tble
state.tble$expected
state.tble$p.value
xkabledply(state.tble$expected, title="Cross table for the Expected Frequencies of Food Deserts in U.S. States")
```
When running the chi-square test on the state variable and desert variable we can once agian reject the null. The output here shows us that the test statistic is 297.53 which is much large than the critical chi-square value for 50 degrees of freedom at 67.505. The p-value is smaller than .05 so these results are statistically significant. 

The chi-square test showed us that we should be able to use the 'Region', 'Urban', and 'State' variables in our model because they will all have a relationship with our dependent variable. However, we will need to assess this further during the model building part of the report. 

# Chapter 2.2 
## Exploratorday Data Analysis: Two Sample T-Test 
Here we are performing two-sample t test. This part of the report seeks to answer this question: Are the means of the continuous or quantitative variables different based on whether or a census tract is a food desert? 

To answer this question the first step was to subset our data to include two samples: one with food deserts and the other with no food deserts. This is similiar to the earlier EDA that we did, but we need a data frame that has excludes any food deserts in order to execute the analysis. 
```{R unpaired two-sample t test}
food_0<-subset(food,Desert==0)
food_1<-subset(food,Desert==1)
### for variable 'POP2010'
t.test(food_0$POP2010,food_1$POP2010)

### for the rest variables
t.test(food_0$OHU2010,food_1$OHU2010)
t.test(food_0$NUMGQTRS,food_1$NUMGQTRS)
t.test(food_0$PovertyRate,food_1$PovertyRate)
t.test(food_0$MedianFamilyIncome,food_1$MedianFamilyIncome)
t.test(food_0$TractLOWI,food_1$TractLOWI)
t.test(food_0$TractKids,food_1$TractKids)
t.test(food_0$TractSeniors,food_1$TractSeniors)
t.test(food_0$TractWhite,food_1$TractWhite)
t.test(food_0$TractBlack,food_1$TractBlack)
t.test(food_0$TractAsian,food_1$TractAsian)
t.test(food_0$TractNHOPI,food_1$TractNHOPI)
t.test(food_0$TractAIAN,food_1$TractAIAN)
t.test(food_0$TractOMultir,food_1$TractOMultir)
t.test(food_0$TractHispanic,food_1$TractHispanic)
t.test(food_0$TractHUNV,food_1$TractHUNV)
t.test(food_0$TractSNAP,food_1$TractSNAP)
```
The result of the two sample t-test showed us a myriad of things: 
The population mean was higher in food deserts. The occupied housing units were higher in tracts that are not classified as food deserts. The occupied group housing units mean were about twice as high in food deserts. The poverty rate mean is higher in food deserts. The median family income mean is 63% higher in tracts not classified as food deserts. The low income population is six times larger in food deserts. The mean of the number of kids is also higher in food deserts but not by too much. The mean of the number of senior residents in a tract is actually higher in areas not classified as food deserts. The mean of the White population is higher in non-food deserts, and the mean of the Black population is higher in food-deserts. The mean of Native Hawaiian and other Pacific Islander populations is higher in food deserts. This matches what we saw during our normality test at the first part of the EDA. The mean of the American Indian and Alaskan Native population is significantly higher in food deserts. We saw this in the first part of the EDA, and will explore this further throughout the report. The mean of multiracial population is higher in food deserts, we saw this in the first part of the EDA, but again the multiracial/other population variable does not tell us much. The mean of the Hispanic population is higher in food deserts. The mean of houses without a car is only slightly larger in food deserts. The mean of people on SNAP benefits is significantly higher in food deserts. 

Overall, the results of our t-test align with the literature around food deserts showing that racial minority populations are more likely to be in a census tract without access to a full-service grocery store along with low-income people who are at or below the federal poverty rate. We have multiple indicators of these populations and the results are aligned with what past research has said. The results of our t-test warrant further investigation into racial disparities, as well as the systemic and institutionalized  racism that has plagued the United States and led to food insecurity along racial lines. 

# Chapter 2.3 Exploratory Data Analysis
## Correlation Matrix 
Here we are plotting a correlation matrix to determine which of our variables are highly correlated with one another. We will use the matrix to help us determine what variables to use and control for multicollinearity.  The dependent variable in our data is a 0 or 1 indicator variable that determines whether or not a census tract is in a food desert, because we are running a logisitical regression we knew that it is not necessary for us to turn the variable into a factor. Thus, we use it here in the correlation matrix, but realize that this does not tell us much based on the nature of the variable.  
```{r Correaltion of Variables on Desert Variable}
food_coronly <- food[c("Desert","POP2010","OHU2010","NUMGQTRS","PovertyRate","MedianFamilyIncome","TractLOWI","TractKids","TractSeniors","TractWhite","TractBlack","TractAsian","TractNHOPI","TractAIAN","TractOMultir","TractHispanic","TractHUNV","TractSNAP")]
corr.food <- cor(food_coronly)
corrplot(corr.food)
```
From the correlation matrix we will look at variables that are at .7 or above to assess their correlation with one another. From this criteria, we can see that the population variables is higly correlated with the occupied housing units, the white population, and the total amount of kids in a census tract. Furthermore, the occupied housing variable is also highly correlated with the white population and total amoutn of kids in a census tract. The low-income population variable is highly correlated with the amount of people receiving SNAP benefits in a census tract. The multiple race/other variable is highly correlated with Hispanic$-$this is interesting because it seems that this variable would be correlated with all the other races, but it is only strongly correlated with the Hispanic tract variable. As such, we will be sure to keep this in mind as we are building our models for the logisitic regression. 

# Chapter 3: Geographic Location and Dispersion of Data 
## Heatmaps 
```{R Heatmap for population sum for different states}
### install.packages("usmap")
### install.packages("ggplot2")

loadPkg("usmap")
loadPkg("ggplot2")
dataforheatmap<-read.csv("E:/gwu/Courses/DATS 6101/project/dataforheatmap.csv")

### map for population of different states in dataset 'food'
plot_usmap(data = dataforheatmap, values = "sumpop", color = "red") + 
  scale_fill_continuous(name = "Population (2010)", label = scales::comma) + 
  theme(legend.position = "right")

### map for proportion of Desert of different states in dataset 'food'
plot_usmap(data = dataforheatmap, values = "Desertp", color = "red") + 
  scale_fill_continuous(name = "Food Desert Proportion", label = scales::comma) + 
  theme(legend.position = "right")

plot_usmap(data = dataforheatmap, values = "Desertp", labels = T, size=0.2) + labs(fill = 'Food Desert Proportion') +   scale_fill_gradientn(colours=rev(heat.colors(10)),na.value="grey90",
                       guide = guide_colourbar(barwidth = 25, barheight = 0.4,
                                               #put legend title on top of legend
                                               title.position = "top")) +theme(legend.position = "bottom",
        legend.title=element_text(size=12), 
        legend.text=element_text(size=10))

```

# Chapter 4: Model Building
## Variable Selection$-$Feature Selection 
Here we are dissecting which variabels we should use in our model based on Adjusted R-Squared, Cp, BIC, and AIC. We are automatically excluding Census Tract and State variable because they have too many levles for this analysis. Additionally, we realize that we should be using bestglm() function to determine what variables to use for a logistic regression, but to have a comprehensive analysis we are going to try regsubsets() and bestglm() functions for model building. We know that our response variable is variable ‘Desert’ which is binary, but linear models still deserve a try because it may provide us with some ideas about variable selection.

### Forward Selection 
```{r Forward Variable Selection}
reg.forward.1 <-regsubsets(Desert ~.-CensusTract-State, data = food, nvmax=19, nbest=1, method="forward")
plot(reg.forward.1, scale = "adjr2", main = "Adjusted R^2")
plot(reg.forward.1, scale = "Cp", main = "CP")
plot(reg.forward.1, scale = "bic", main = "BIC")


#model_forward_adjr2<-lm(Desert~.-TractBlack,data = food)
model_forward_Cp<-lm(Desert~.-TractBlack-TractWhite,data = food)
model_forward_bic<-lm(Desert~.-TractBlack-TractWhite-OHU2010-TractKids-TractSeniors-TractNHOPI-TractOMultir,data = food)
#summary(model_forward_adjr2)
#summary(model_forward_Cp)
#summary(model_forward_bic)

#anova(model_forward_adjr2,model_forward_Cp)
#anova(model_forward_adjr2,model_forward_bic)
#anova(model_forward_Cp,model_forward_bic)
```
We know that the difference between model_forward_adjr2 and model_forward_Cp is TractWhite,
the summary of model_forward_adjr2 indicated that it should not be included in the model, and anova() function's F test gave the same conclusion, for now, model_forward_Cp is a better choice. Then, we compared model_forward_Cp and model_forward_bic, together with result of summary of Model_forward_Cp, we can conclude that for forward selection, the variables in model_forward_Cp are good for now.

### Backwards Selection 
```{R Backward Variable Selection}
# Backward Selection
reg.bkwd.1 <- regsubsets(Desert~.-CensusTract-State, data= food, nvmax=19, nbest=1, method="backward")
plot(reg.bkwd.1, scale = "adjr2", main = "Adjusted R^2")
plot(reg.bkwd.1, scale = "Cp", main = "CP")
plot(reg.bkwd.1, scale = "bic", main = "BIC")

# Deciding Best Variables with Backward Selection Not including Highly Correlated Variables 
reg.bkwd.2 <- regsubsets(Desert~.-CensusTract-State-OHU2010-TractWhite-TractKids-TractLOWI-TractOMultir, data= food, nvmax=19, nbest=1, method="backward")
plot(reg.bkwd.2, scale = "adjr2", main = "Adjusted R^2")
plot(reg.bkwd.2, scale = "Cp", main = "CP")
plot(reg.bkwd.2, scale = "bic", main = "BIC")

#model_backward_adjr2<-lm(Desert~.-TractHispanic,data = food)
#model_backward_BIC<-lm(Desert~.-MedianFamilyIncome-TractAsian-TractNHOPI-TractHispanic-TractBlack-TractWhite-TractOMultir,data = food)
#summary(model_backward_adjr2)
#summary(model_backward_BIC)

#anova(model_backward_adjr2,model_backward_BIC)
```


Cp and Adjusted R-square gave the same results, we only compare with BIC. 

Based on the results, model_backward_adjr2 is a better choice. And to make the sequential selection easier, we removed variable 'TractBlack', 'TractWhite' and 'TractHispanic'

### Sequential Selection 
```{R Sequential Variable Selection}
# Sequential Selection 
reg.seq.1 <- regsubsets(Desert~.-CensusTract-State-TractBlack-TractHispanic, data= food, nvmax=19, nbest=1, method="seqrep")
plot(reg.seq.1, scale = "adjr2", main = "Adjusted R^2")
plot(reg.seq.1, scale = "Cp", main = "CP")
plot(reg.seq.1, scale = "bic", main = "BIC")

reg.seq.2 <- regsubsets(Desert~.-CensusTract-State-OHU2010-TractWhite-TractKids-TractLOWI-TractOMultir, data= food, nvmax=19, nbest=1, method="seqrep")
plot(reg.seq.2, scale = "adjr2", main = "Adjusted R^2")
plot(reg.seq.2, scale = "Cp", main = "CP")
plot(reg.seq.2, scale = "bic", main = "BIC")

#model_seq_adjr2<-lm(Desert~.-CensusTract-State-TractHispanic-TractBlack-TractWhite, data= food)
#model_seq_BIC<-lm(Desert~.-CensusTract-State-TractHispanic-TractBlack-TractWhite-TractAsian-TractSNAP, data= food)

#summary(model_seq_adjr2)
#summary(model_seq_BIC)

#anova(model_seq_adjr2,model_seq_BIC)
```

Cp and adjusted R-square gave the same result, so we only compare it with the model from BIC

We got a p-value larger than 0.05 from output of F test but not very obviously significant, and from summary of model_seq_adjr2, we can see that variable 'TractAsian' should be excluded. 

### Exhaustive Selection
```{R Exhaustive Variable Selection}
reg.exhaustive <-regsubsets(Desert~.-CensusTract-State-TractHispanic-TractBlack-TractSNAP, data = food, nvmax=19, nbest=1, method="exhaustive")
plot(reg.exhaustive, scale = "adjr2", main = "Adjusted R^2")
plot(reg.exhaustive, scale = "Cp", main = "CP")
plot(reg.exhaustive, scale = "bic", main = "BIC")
```

We tried exhaustive method here as an additional part, this method is only available when number of possible predictor variables is less than 20. It might not be very wise for us to follow the suggestions given by exhaustive method, because those variables gave significant p-values in the forward, backward and sequential selection. 


Again, we know that our variable Y is desert which is binary, logistic regression should be used, but linear models still deserve a try because it may give us some surprise about variable selection.

We did not include variable 'State' in our model because there are too many levels, it increased the difficulty for us to conclude, so we drop it in the process of plotting, but with no doubts, variable 'State' should be kept in the linear model try lm() part because with so many levels, at least some of them are significant, and this has been proved by the summary() function in the next step.

# GLM Best fucntion for logisitc regression -- Variable Selection 
TO simplify the process and protect information from dataset, we chose to use 0.01 as the significance level. Now, variable 'OHU2010' and 'POP2010', variable '$Region' and 'Urban', 
variable 'PovertyRate' and 'Urban', variable 'PovertyRate' and 'MedianFamilyIncome', variable 'POP2010' and 'NUMGQTRS' are not independent of each other. And it is not necessary for us to do the same test for the rest variables starting with 'Tract' since all of them are numbers of different group in the tract, in common sense, they are certainly not independent. Basically, we are required to remove these variables, however, if we really do that, we may only have five or six variables left in total, so, in order to proceed to model building part, we did not make big changes here, but this part will benefit optimization and future research if necessary.

### Bestglm Variable Selection 
```{r bestglm Method}
library(bestglm)
best.glm <- within(food, {
  CensusTract <- NULL 
  TractLOWI <- NULL 
  OHU2010 <- NULL 
  TractOMultir <- NULL 
  TractWhite <- NULL 
  TractKids <- NULL 
  Region <- NULL 
  State <- NULL 
  y <-  Desert
  Desert <- NULL
})
best.glm.nopop <- within(food, {
  CensusTract <- NULL 
  POP2010 <- NULL 
  TractWhite <- NULL 
  TractKids <- NULL 
  Region <- NULL 
  State <- NULL 
  y <-  Desert
  Desert <- NULL
})

#best.glm
res.best.glm <- bestglm(Xy = best.glm) 
#res.best.glm$BestModels
nopop.glm <- bestglm(Xy=best.glm.nopop)
res.best.glm$BestModel
nopop.glm$BestModel
#nopop.glm$BestModels
```

# Chapter 4.1: Model Selection 
## AIC Table$-$Best Fit Model 
Logistic Regression and Classification 
Here we are using AIC levels to determine the best fit model to use for our logisitcal regression. 
```{r}
# Model Building Logistic Regression Based on Featured Selection 
#Model F - Forward Selection Best Model 
model.f <- glm(Desert~.-CensusTract-TractBlack, data=food, family=binomial)
#model.f.corr <- Desert~.-OHU2010-TractWhite-TractKids-TractLOWI-TractOMultir, data=food, family=binomial)
#summary(model.a)
#exp(model.a$coefficients)
# Everything except CensusTract and State
model.b <- glm(Desert~.-CensusTract-TractHispanic, data=food, family="binomial")
#model.b.corr <- glm(Desert~.-CensusTract-OHU2010-TractWhite-TractKids-TractLOWI-Tract0Multir, data=food, family=binomial)
# Using Exhaustive Feature Selection Model 
model.seq <- glm(Desert~.-CensusTract-TractSNAP, data=food, family=binomial)
model.exhaustive <- glm(Desert~.-CensusTract-TractSNAP-TractBlack-TractHispanic, data=food, family="binomial")
# Taking out variables that were highly correlated with other variables 
model.corr <- glm(Desert~.-CensusTract-OHU2010-TractWhite-TractKids-TractLOWI-TractOMultir, data=food, family="binomial")
# Taking out Racial indicators 
glm_newfood_fac_Desert<-glm(Desert~.-CensusTract-TractHispanic-TractBlack-TractWhite-TractAsian-TractSNAP,data = food,family = "binomial")
emptyglm<-glm(Desert~1,data=food,family = binomial)
# Using Forward Selection Model Not worrying about correlated Variables 
forwards_2<-glm(Desert ~ MedianFamilyIncome + State + Urban + TractLOWI + 
    TractHUNV + TractHispanic + TractAsian + NUMGQTRS + TractAIAN + 
    TractKids + TractSNAP + TractSeniors + POP2010 + OHU2010 + 
    PovertyRate,data=food,family = binomial)
# Using Forward Selection Taking Out Correlated Variables 
forwards2_corr<-glm(Desert ~ MedianFamilyIncome + State + Urban + 
    TractHUNV + TractHispanic + TractAsian + NUMGQTRS + TractAIAN + 
     TractSNAP + TractSeniors + POP2010  + 
    PovertyRate,data=food,family = binomial)
# Using Backwards Selection Model not worrying about correlated variables
#backwards_2<-glm(Desert~.-CensusTract-TractHispanic, data=food, family="binomial")
#Using Backwards Selection Taking out Correlated Variables 
#backwards2_corr <- glm(Desert~.-CensusTract-TractLOWI-TractKids-OHU2010-TractHispanic,data=food,family = binomial)
# Using Selection Based on Literature
model.lit <- glm(Desert~State + Urban + Region + TractBlack + TractAsian + TractLOWI + PovertyRate + TractAIAN + TractHispanic +TractOMultir+ TractNHOPI+TractHUNV+MedianFamilyIncome+POP2010, data=food, family="binomial")
# Model from bestglm() 
bestglm.1 <- glm(Desert~Urban+NUMGQTRS+PovertyRate+MedianFamilyIncome+TractBlack+TractAsian+TractHispanic+TractHUNV+TractSNAP+TractSeniors+TractAIAN, data=food, family= binomial)
# Model from bestglm() 2 
bestglm.2 <- glm(Desert~ Urban+OHU2010+NUMGQTRS+PovertyRate+MedianFamilyIncome+TractLOWI+TractAsian+TractAIAN+TractHispanic+TractOMultir+TractHUNV, data=food, family=binomial)
# Model AIC Levels 
models <- list(model.f, model.b, model.seq, model.exhaustive, model.corr, glm_newfood_fac_Desert, emptyglm,forwards_2, forwards2_corr, model.lit, bestglm.1, bestglm.2)
model.names <- c("model.f", "model.b", "model.seq", "model.exhaustive", "model.corr", "glm_newfood_fac_Desert", "emptyglm","forwards_2", "forwards2_corr", "model.lit", "bestglm.1", "bestglm.2")
aictab(cand.set=models, modnames=model.names)
forwards_2$deviance
model.f$deviance
model.seq$deviance
model.b$deviance
model.exhaustive$deviance
glm_newfood_fac_Desert$deviance
model.lit$deviance
bestglm.2$deviance
forwards2_corr$deviance
model.corr$deviance
bestglm.1$deviance
emptyglm$deviance
```

#Chapter 4.2: Logistic Regression 
Here we are running the logistic regression on the best fit model as well as a model to control for multicollinearity on the best fit model.
```{r}
forwards_2<-glm(Desert ~ MedianFamilyIncome + State + Urban + TractLOWI + 
    TractHUNV + TractHispanic + TractAsian + NUMGQTRS + TractAIAN + 
    TractKids + TractSNAP + TractSeniors + POP2010 + OHU2010 + 
    PovertyRate,data=food,family = binomial)
summary(forwards_2)
exp(forwards2_corr$coefficients)
plot(forwards_2)
```

```{r}
###Model Building
## Change variable 'Desert' to factor variable here and the new dataset is named as newfood now
newfood<-food
newfood$Desertfactor<-as.factor(newfood$Desert)
newfood<-newfood[,-8]
#glm_food_int_Desert<-glm(Desertfactor~.-CensusTract,data = newfood,family = "binomial")
#summary(glm_food_int_Desert)

glm_newfood_fac_Desert<-glm(Desertfactor~.-CensusTract-TractHispanic-TractBlack-TractWhite-TractAsian-TractSNAP,data = newfood,family = "binomial")
#summary(glm_newfood_fac_Desert)
#exp(glm_newfood_fac_Desert$coefficients)

## build an empty and full generalised linear model
emptyglm<-glm(Desertfactor~1,data=newfood,family = binomial)
#summary(emptyglm)

fullglm<-glm(Desertfactor~.-CensusTract,data=newfood,family = binomial)
#summary(fullglm)

forwards<-step(emptyglm,scope=list(lower=formula(emptyglm),upper=formula(fullglm)),direction = "forward")
formula(forwards)
summary(forwards)
### The output of summary(forwards) indicates that variable 'TractNHOPI' has a p-value is 0.136183

forwards_2<-glm(Desertfactor ~ MedianFamilyIncome + State + Urban + TractLOWI +
    TractHUNV + TractHispanic + TractAsian + NUMGQTRS + TractAIAN + 
    TractKids + TractSNAP + TractSeniors + POP2010 + OHU2010 + 
    PovertyRate,data=newfood,family = binomial)
#summary(forwards_2)

### Backwards
#backwards<-step(fullglm,scope=list(lower=formula(emptyglm),upper=formula(fullglm)),direction = "backward")
#formula(backwards)
#summary(backwards)

### Let's drop the variable 'TractNHOPI' based on the p-value
backwards_2<-glm(Desertfactor~ State + Urban + POP2010 + OHU2010 + NUMGQTRS + 
  PovertyRate + MedianFamilyIncome + TractLOWI + TractKids + 
    TractSeniors + TractAsian + TractAIAN + TractHispanic + 
    TractHUNV + TractSNAP,data=newfood,family = binomial)
summary(backwards_2)

forwards_2$deviance;backwards_2$deviance
### the two models gave the same deviance, hence backwards_2 is our best generalized linear model for now

### Multicollinearity
vif(backwards_2)


plot(newfood$Desertfactor,predict(backwards_2))

plot(backwards_2)

back2_logit<-glm(Desertfactor~State + Urban + POP2010 + OHU2010 + NUMGQTRS +    PovertyRate + MedianFamilyIncome + TractLOWI + TractKids + 
TractSeniors + TractAsian + TractAIAN + TractHispanic + 
TractHUNV + TractSNAP,data=newfood, family = binomial(link = "logit"))
summary(back2_logit)

### No improvements using logit option

### Let's remove variables according to the corrleation matrix, to simplify the process, we chose to set our criterion as 0.8
backwards_2_withoutOHU2010<-glm(Desertfactor ~ State + Urban + POP2010 + NUMGQTRS + 
    PovertyRate + MedianFamilyIncome + TractLOWI + TractKids + 
    TractSeniors + TractAsian + TractAIAN + TractHispanic + 
    TractHUNV + TractSNAP,data=newfood,family = binomial)
summary(backwards_2_withoutOHU2010)
backwards_2_withoutOHU2010$deviance
anova(backwards_2,backwards_2_withoutOHU2010,test = "Chisq")

backwards_2_withoutPOP2010<-glm(Desertfactor ~ State + Urban + OHU2010 + NUMGQTRS + 
   PovertyRate + MedianFamilyIncome + TractLOWI + TractKids + 
   TractSeniors + TractAsian + TractAIAN + TractHispanic + 
    TractHUNV + TractSNAP,data=newfood,family = binomial)
summary(backwards_2_withoutPOP2010)
backwards_2_withoutPOP2010$deviance
anova(backwards_2,backwards_2_withoutPOP2010,test = "Chisq")

backwards_2_withoutTkids<-glm(Desertfactor ~ State + Urban + POP2010 + OHU2010 + #NUMGQTRS + 
    PovertyRate + MedianFamilyIncome + TractLOWI + TractSeniors + TractAsian + TractAIAN + TractHispanic + 
    TractHUNV + TractSNAP,data=newfood,family = binomial)
summary(backwards_2_withoutTkids)
backwards_2_withoutTkids$deviance
anova(backwards_2,backwards_2_withoutTkids,test = "Chisq")
vcov(backwards_2)
vcov(backwards_2_withoutTkids)

vif(backwards_2_withoutTkids)
### still not showing good vif's

### Based on the deviance, the lowest one is for backwards_2_withoutTkids, we may choose it, but if we check anova()'s result, we see that variable 'TractKids' is good to be kept, our decision depends on the priority comparison between collinearity and model evaluation. 


### Check Assumptions of logistic regression
```

We have not changed the variable 'Desert' to factor variable until the model building part since correlation matrix will need variable 'Desert' to be numerical, and all test before gave same results for 'Desert' in factor format and numerical format.

And based on the outputs of the two models above, we saw that: No matter variable 'Desert' is numerical or categorical, we get the same results, but for stringency, we will use variable 'Desertfactor' in the dataset named as 'newfood'.

For the variable selection process, we saw multicollinearity is not good, this is an inborn disadvantage of our dataset, we have mentioned this in Chi-Square test part. Further detection is needed.

# Chapter 5: Conclusion



plot_usmap(data = dataforheatmap, values = "Desertp", labels = T, size=0.2) + labs(fill = 'Food Desert Proportion') +   scale_fill_gradientn(colours=rev(heat.colors(10)),na.value="grey90",
                       guide = guide_colourbar(barwidth = 25, barheight = 0.4,
                                               #put legend title on top of legend
                                               title.position = "top")) +theme(legend.position = "bottom",
        legend.title=element_text(size=12), 
        legend.text=element_text(size=10))

```
### Logistic Regression Model Diagnostics
```{R Model Diagnostics}
loadPkg("pROC")
loadPkg("caret")
index<-sample(1:nrow(food),0.6*nrow(food))
food_train<-food[index,]
food_test<-food[-index,]
food_test$Desert<-as.factor(food_test$Desert)
predicted<-predict(forwards_2,food_test,type = "response")

plot.roc(food_test$Desert,predicted, show.stats = TRUE,lty = "solid",legend="topright")
summary(plot.roc(food_test$Desert,predicted))
unloadPkg("caret")
loadPkg("ModelMetrics")
confusionMatrix(food_test$Desert,predicted)
```


#NNK Outlier Detection Using Kth Nearest Neighbor Distance Method
#Takes a dataset and finds its outliers using distance-based method



#KNN Portion

```{r}
#Loading the data set

food_k <- read.csv("food.csv") 

#K mean dataframe (food)
food_k <- food

#make State factor?
food_k$State <- factor(food_k$State)
loadPkg("FNN")

#seperate dataframes
food_k <- as.data.frame(scale(food[1:22], center = TRUE, scale = TRUE))

set.seed(1000)
#Need to create test and training datasets so must create a sample set ecompassing two sets of data.
food_sample <- sample(2, nrow(food_k), replace=TRUE, prob=c(0.67, 0.33))

#Use new variable to create the new test/train outputs.
food_training <- food_k[food_sample==1, 1:22]
food_test <- food_k[food_sample==2, 1:22]

#Create Y variables used to put in KNN function
food.trainLabels <- food[food_sample==1, 22]
food.testLabels <- food[food_sample==2, 22]

#Should deploy model but reading back error message
food_pred <- knn(train = food_training, test = food_test, cl=food.trainLabels, k = 7)

```



```



```


# Chapter 4: Conclusion 











